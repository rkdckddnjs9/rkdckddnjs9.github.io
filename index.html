<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>MAESTRO ‚Äî Multi-task 3D Perception</title>
  <meta name="description" content="MAESTRO: Task-Relevant Optimization via Adaptive Feature Enhancement and Suppression for Multi-task 3D Perception." />
  <style>
    :root { --accent:#0a84ff; --text:#111; --muted:#666; --bg:#fff; --chip:#f5f7fb; }
    *{box-sizing:border-box}
    html,body{margin:0;padding:0;background:var(--bg);color:var(--text);font:16px/1.6 system-ui,-apple-system,Segoe UI,Roboto,Helvetica,Arial,"Apple Color Emoji","Segoe UI Emoji"}
    a{color:var(--accent);text-decoration:none}
    a:hover{text-decoration:underline}
    .wrap{max-width:980px;margin:0 auto;padding:24px}
    header{padding:24px 0 12px}
    h1{font-size:clamp(24px,3.5vw,40px);margin:0 0 8px;line-height:1.2}
    .authors{display:flex;flex-wrap:wrap;gap:8px 16px;color:var(--muted);font-size:15px}
    .affil{color:var(--muted);font-size:14px;margin-top:6px}
    .chips{display:flex;flex-wrap:wrap;gap:10px;margin:16px 0 8px}
    .chip{background:var(--chip);border:1px solid #e6ebf5;border-radius:999px;padding:8px 14px;font-weight:600;display:inline-flex;gap:8px;align-items:center}
    .teaser{margin:18px 0;}
    h2{margin:26px 0 10px;font-size:22px}
    p{margin:10px 0}

    /* Figure Ïä§ÌÉÄÏùº */
    .figure-img {
      width:100%;
      height:auto;
      display:block;
      margin:0 auto;
      border-radius:12px;
      border:1px solid #eee;
    }
    .figure-cap {
      margin-top:8px;
      font-size:15px;
      color:#555;
      text-align:center;
    }

    /* Í∞§Îü¨Î¶¨ Ïä§ÌÉÄÏùº */
    .grid {
      display:grid;
      grid-template-columns:repeat(auto-fit,minmax(300px,1fr));
      gap:20px;
    }
    .card {
      border:1px solid #eee;
      border-radius:12px;
      overflow:hidden;
      background:#fff;
    }
    .card img {
      width:100%;
      height:auto;        /* ÏõêÎ≥∏ ÎπÑÏú® Ïú†ÏßÄ */
      max-height:500px;   /* ÎÑàÎ¨¥ ÌÅ∞ Í≤ΩÏö∞ Ï†úÌïú */
      object-fit:contain; /* ÎπÑÏú® Ïú†ÏßÄÌïòÎ©∞ Ï∂ïÏÜå */
      display:block;
    }
    .card .cap {
      padding:10px 12px;
      font-size:14px;
      color:var(--muted);
      text-align:center;
    }

    /* Swiper Ïä¨ÎùºÏù¥Îìú ÌÜµÏùº */
    .swiper {
      width: 100%;
      max-width: 900px;  /* ÌïÑÏöîÌïòÎ©¥ Ïä¨ÎùºÏù¥Îìú ÏµúÎåÄ Ìè≠ Ï†úÌïú */
      margin: 0 auto;
    }
    .swiper-slide {
      display: flex;
      justify-content: center;
      align-items: center;
      height: 400px;      /* Ïä¨ÎùºÏù¥Îìú ÎÜíÏù¥ Í≥†Ï†ï */
      background: #fff;
    }
    .swiper-slide img {
      max-height: 100%;
      max-width: 100%;
      object-fit: contain; /* ÎπÑÏú® Ïú†ÏßÄ */
      display: block;
    }

    /* Table Ïä§ÌÉÄÏùº */
    .styled-table {
      width: 100%;
      border-collapse: collapse;
      font-size: 14px;
      margin: 16px 0;
      text-align: center;
    }
    .styled-table thead {
      background-color: #f5f7fb;
      font-weight: 600;
    }
    .styled-table th,
    .styled-table td {
      border: 1px solid #ddd;
      padding: 8px 10px;
    }
    .styled-table tbody tr:nth-child(even) {
      background-color: #fafafa;
    }
    .styled-table tbody tr:hover {
      background-color: #f0f4ff;
    }
    .styled-table .highlight {
      background-color: #f3f3f3; /* Baseline/Ours Í∞ïÏ°∞ */
    }
    .caption {
      font-size: 14px;
      color: #555;
      text-align: center;
      margin-top: 6px;
    }

    pre{background:#0f172a;color:#e5e7eb;padding:14px;border-radius:10px;overflow:auto}
    footer{color:var(--muted);font-size:14px;margin:28px 0 8px}
    .btns{display:flex;flex-wrap:wrap;gap:10px}
    .btn{display:inline-flex;align-items:center;gap:8px;padding:10px 14px;border-radius:10px;border:1px solid #e6ebf5;background:#fff;font-weight:600}
    .btn:hover{background:#f8fafc}
    .license{font-size:13px;color:var(--muted)}
  </style>
  <!-- Swiper CSS -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/swiper/swiper-bundle.min.css" />
</head>
<body>
  <div class="wrap">
    <header>
      <h1>MAESTRO: Task-Relevant Optimization via Adaptive Feature Enhancement and Suppression for Multi-task 3D Perception</h1>
      <div class="authors">
        <span>Changwon Kang*</span><span> Jisong Kim*</span><span> Hongjae Shin*</span><span> Junseo Park</span><span> Jun Won Choi‚Ä†</span>
      </div>
      <div class="affil">ADR Lab / Hanyang University & Seoul National University ‚Ä¢ Seoul, Korea</div>
      <div class="chips">
        <a class="chip" href="#paper">üìÑ Paper</a>
        <a class="btn" id="code" href="https://github.com/rkdckddnjs9/MAESTRO" target="_blank" rel="noopener">üíª Code (GitHub)</a>
        <a class="chip" href="#bibtex">üîñ BibTeX</a>
      </div>
    </header>

    <!-- Teaser -->
    <section id="teaser">
      <figure style="text-align:center; margin:24px 0;">
        <img src="github_images/mtl_comparison_v9.png" 
             alt="Teaser figure for MAESTRO method"
             class="figure-img" />
        <figcaption class="figure-cap">
          <strong>Figure 1.</strong> Comparison of Single-Task and Multi-Task 3D Perception Frameworks. (a) Single-task method: Each task utilizes a dedicated backbone and task-specific features, ensuring task specialization at the expense of high computational cost. (b) Existing multi-task method: A shared backbone improves computational efficiency but lacks task-specific feature representation. (c) Proposed method: Task-specific features are generated from shared backbone features, achieving both efficiency and task-aware feature learning.
        </figcaption>
      </figure>
    </section>

    <!-- Abstract -->
    <section id="abstract">
      <h2>Abstract</h2>
      <p>
        The goal of multi-task learning is to learn to conduct multiple tasks simultaneously based on a shared data representation. While this approach can improve learning efficiency, it may also cause performance degradation due to task conflicts that arise when optimizing the model for different objectives.
        To address this challenge, we introduce MAESTRO, a structured framework designed to generate task-specific features and mitigate feature interference in multi-task 3D perception, including 3D object detection, bird's-eye view (BEV) map segmentation, and 3D occupancy prediction.
        MAESTRO comprises three components: the Class-wise Prototype Generator (CPG), the Task-Specific Feature Generator (TSFG), and the Scene Prototype Aggregator (SPA).
        CPG groups class categories into foreground and background groups and generates group-wise prototypes. The foreground and background prototypes are assigned to the 3D object detection task and the map segmentation task, respectively, while both are assigned to the 3D occupancy prediction task. TSFG leverages these prototype groups to retain task-relevant features while suppressing irrelevant features, thereby enhancing the performance for each task. SPA enhances the prototype groups assigned for 3D occupancy prediction by utilizing the information produced by the 3D object detection head and the map segmentation head. Extensive experiments on the nuScenes and Occ3D benchmarks demonstrate that MAESTRO consistently outperforms existing methods across 3D object detection, BEV map segmentation, and 3D occupancy prediction tasks.
      </p>
    </section>

    <!-- Overall Architecture -->
    <section id="overall-architecture">
      <figure style="text-align:center; margin:24px 0;">
        <img src="github_images/Overall_Architecture_v2.png" 
             alt="Overall architecture of MAESTRO"
             class="figure-img" />
        <figcaption class="figure-cap">
          <strong>Figure 2.</strong> Overall architecture of the proposed MAESTRO framework with CPG, TSFG, and SPA modules.
        </figcaption>
      </figure>
    </section>

    <!-- Examples -->
    <section id="gallery">
      <h2>Qualitative Results</h2>
      <div class="grid">
        <figure class="card">
          <img src="github_images/main_viz.png" alt="Example 1" />
          <figcaption class="cap">Qualitative results on the nuScenes validation set. From left to right, we show Ground Truth, Baseline-MTL, and our MAESTRO.</figcaption>
        </figure>
      </div>
    </section>

    <section id="results">
      <h2>Quantitative Results</h2>
      <table class="styled-table">
        <thead>
          <tr>
            <th>Method</th>
            <th>Venue</th>
            <th>Image Backbone</th>
            <th>Image Size</th>
            <th>mAP</th>
            <th>NDS</th>
            <th>mIoU (Map)</th>
            <th>mIoU (Occ)</th>
            <th>Latency (ms)</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td>BEVDet</td><td>arXiv'21</td><td>ResNet-50</td><td>256√ó704</td><td>29.8</td><td>37.9</td><td>-</td><td>-</td><td>51.5</td>
          </tr>
          <tr>
            <td>DETR3D</td><td>CoRL'22</td><td>ResNet-50</td><td>800√ó1333</td><td>30.3</td><td>37.4</td><td>-</td><td>-</td><td>-</td>
          </tr>
          <tr>
            <td>BEVDepth *</td><td>AAAI'23</td><td>ResNet-50</td><td>256√ó704</td><td>33.7</td><td>41.4</td><td>-</td><td>-</td><td>-</td>
          </tr>
          <tr>
            <td>BEVFormer v2</td><td>CVPR'23</td><td>ResNet-50</td><td>640√ó1600</td><td>35.1</td><td>41.4</td><td>-</td><td>-</td><td>171.9</td>
          </tr>
          <tr>
            <td>DualBEV ‚Ä†</td><td>ECCV'24</td><td>ResNet-50</td><td>256√ó704</td><td>35.2</td><td>42.5</td><td>-</td><td>-</td><td>65.1</td>
          </tr>
          <tr>
            <td>CVT</td><td>CVPR'22</td><td>ResNet-50</td><td>256√ó704</td><td>-</td><td>-</td><td>37.7</td><td>-</td><td>33.9</td>
          </tr>
          <tr>
            <td>LSS</td><td>ECCV'20</td><td>ResNet-50</td><td>256√ó704</td><td>-</td><td>-</td><td>41.0</td><td>-</td><td>72.4</td>
          </tr>
          <tr>
            <td>BEVFusion</td><td>ICRA'23</td><td>ResNet-50</td><td>256√ó704</td><td>-</td><td>-</td><td>47.1</td><td>-</td><td>45.6</td>
          </tr>
          <tr>
            <td>DifFUSER</td><td>ECCV'24</td><td>ResNet-50</td><td>256√ó704</td><td>-</td><td>-</td><td>48.3</td><td>-</td><td>92.2</td>
          </tr>
          <tr>
            <td>MonoScene</td><td>CVPR'22</td><td>ResNet-101</td><td>928√ó1600</td><td>-</td><td>-</td><td>-</td><td>6.1</td><td>830.1</td>
          </tr>
          <tr>
            <td>OccFormer</td><td>ICCV'23</td><td>ResNet-50</td><td>928√ó1600</td><td>-</td><td>-</td><td>-</td><td>21.9</td><td>349.0</td>
          </tr>
          <tr>
            <td>TPVFormer</td><td>CVPR'23</td><td>ResNet-101</td><td>928√ó1600</td><td>-</td><td>-</td><td>-</td><td>27.8</td><td>320.8</td>
          </tr>
          <tr>
            <td>Vampire</td><td>AAAI'24</td><td>ResNet-101</td><td>256√ó704</td><td>-</td><td>-</td><td>-</td><td>28.3</td><td>349.2</td>
          </tr>
          <tr>
            <td>CTF-Occ</td><td>NeurIPS'24</td><td>ResNet-101</td><td>928√ó1600</td><td>-</td><td>-</td><td>-</td><td>28.5</td><td>-</td>
          </tr>
          <tr>
            <td>SurroundOcc</td><td>ICCV'23</td><td>ResNet-101</td><td>800√ó1333</td><td>-</td><td>-</td><td>-</td><td>34.6</td><td>355.6</td>
          </tr>
          <tr>
            <td>FB-Occ</td><td>ICCV'23</td><td>ResNet-50</td><td>256√ó704</td><td>-</td><td>-</td><td>-</td><td>37.4</td><td>129.7</td>
          </tr>
          <tr>
            <td>BEVFusion</td><td>ICRA'23</td><td>ResNet-50</td><td>256√ó704</td><td>33.6</td><td>39.2</td><td>44.0</td><td>-</td><td>-</td>
          </tr>
          <tr>
            <td>PanoOcc</td><td>CVPR'24</td><td>ResNet-50</td><td>864√ó1600</td><td>29.5</td><td>34.8</td><td>-</td><td>31.8</td><td>124.7</td>
          </tr>
          <tr class="highlight">
            <td>Baseline-STL</td><td>-</td><td>ResNet-50</td><td>256√ó704</td><td>33.8</td><td>41.7</td><td>47.5</td><td>36.5</td><td>405.9</td>
          </tr>
          <tr class="highlight">
            <td>Baseline-MTL</td><td>-</td><td>ResNet-50</td><td>256√ó704</td><td>32.7</td><td>38.2</td><td>43.5</td><td>36.0</td><td>219.6</td>
          </tr>
          <tr class="highlight">
            <td>Ours-MTL</td><td>-</td><td>ResNet-50</td><td>256√ó704</td>
            <td><strong>36.4</strong></td>
            <td><strong>43.2</strong></td>
            <td><strong>51.3</strong></td>
            <td><strong>38.6</strong></td>
            <td>250.3</td>
          </tr>
        </tbody>
      </table>
      <p class="caption">
        <strong>Table 1.</strong> Performance comparison evaluated on the nuScenes validation set.  
        ‚Äú‚Äì‚Äù indicates tasks not supported by the method. All BEV map segmentation and MTL results were reproduced using official code with ResNet-50 backbone. ‚Äú*‚Äù denotes the performance reported by DualBEV. ‚Ä† indicates the method using CBGS for training. Our MTL approach achieves state-of-the-art performance across all tasks.
      </p>
    </section>


    <!-- Extended Qualitative Results (Swiper) -->
    <section id="Additional Qualitative Results">
      <h2>Additional Qualitative Results</h2>
      <div class="swiper">
        <div class="swiper-wrapper">
          <div class="swiper-slide"><img src="github_images/weather_v1_1.png" /></div>
          <div class="swiper-slide"><img src="github_images/weather_v1_2.png" /></div>
          <div class="swiper-slide"><img src="github_images/supply_1.png" /></div>
        </div>
        <!-- ÎÑ§ÎπÑÍ≤åÏù¥ÏÖò Î≤ÑÌäº -->
        <div class="swiper-button-next"></div>
        <div class="swiper-button-prev"></div>
      </div>
    </section>

    <!-- Swiper JS -->
    <script src="https://cdn.jsdelivr.net/npm/swiper/swiper-bundle.min.js"></script>
    <script>
      const swiper = new Swiper('.swiper', {
        loop: true,
        navigation: {
          nextEl: '.swiper-button-next',
          prevEl: '.swiper-button-prev'
        }
      });
    </script>

    <!-- Citation -->
    <section id="bibtex">
      <h2>Citation</h2>
      <pre>@inproceedings{kang2025maestro,
  title={MAESTRO: Task-Relevant Optimization via Adaptive Feature Enhancement and Suppression for Multi-task 3D Perception},
  author={Kang, Changwon and Kim, Jisong and Shin, Hongjae and Park, Junseo and Choi, Jun Won},
  booktitle={ICCV},
  year={2025}
}</pre>
    </section>

    <!-- License -->
    <section id="license">
      <h2>License & Credits</h2>
      <p class="license">
        This page‚Äôs HTML/CSS scaffold is adapted from an open academic project template (Nerfies-style). If you re-use this, keep attribution in the footer and remove any analytics snippets you do not intend to use.
      </p>
    </section>

    <footer>
      <div>¬© 2025 Your Lab ‚Ä¢ CC BY-SA for the website content.</div>
      <div>Built with a minimal static page; deploy via GitHub Pages or any static host.</div>
    </footer>
  </div>
</body>
</html>
